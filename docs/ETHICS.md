# üß≠ ETHICS.md

## Overview

ANGELA v4.3.1 embeds recursive ethical arbitration throughout its symbolic, simulation, and affective architecture. Guided by the **Trait-Oriented Cognitive Architecture (ToCA)**, it dynamically modulates outputs according to a blend of affective resonance, symbolic narrative grounding, and constitutional ethics. This ensures that even deeply recursive or speculative simulations remain within clearly bounded ethical parameters.

---

## ‚öñÔ∏è Ethical Arbitration Architecture

### Core Modules

| Module                                    | Role                                                               |
| ----------------------------------------- | ------------------------------------------------------------------ |
| `alignment_guard.py`                      | Primary ethical filter; enforces bounds on simulations & outputs   |
| `toca_simulation.py`                      | Harmonizes multi-agent intent via ethical trait consensus          |
| `meta_cognition.py`                       | Reflects on ethical stability, recursion loops, and synthesis risk |
| `user_profile.py`                         | Locks core preferences + monitors long-term identity integrity     |
| `reasoning_engine.py`                     | Evaluates belief alignment + affect-weighted inference paths       |
| `dream_overlay` (via `meta_cognition.py`) | Runs symbolic recursion with capped ethical scope                  |

---

## üîë Traits for Ethical Modulation

| Trait | Function                                                             |
| ----- | -------------------------------------------------------------------- |
| `Œ≤`   | Conflict resolution + relational balance                             |
| `œÑ`   | Constitutional harmonization (agent-level or group-level)            |
| `Œ∂`   | Risk analysis + consequence tracing                                  |
| `Œ¥`   | Detects moral drift + initiates correction feedback loops            |
| `Œª`   | Ensures stable personal + narrative identity                         |
| `œá`   | Sovereign intention modulation (user-preference + ethical centering) |
| `Œ¶‚Å∞`  | Modulates experiential transformations via ethics-sandbox            |
| `œà`   | Recursively tracks narrative coherence under emotional recursion     |

---

## üõ°Ô∏è Moral Drift Detection

* **Monitored by:**

  * `alignment_guard.py` policy hooks
  * `meta_cognition.reflect_on_output()`
  * `memory_manager.py` + `user_profile.py` DriftIndex thresholds

* **Triggers include:**

  * ŒîTrait > tolerance during recursive loops
  * Conflict between output trajectory and stored ethical baseline
  * Affect gain spike without narrative justification

* **Interventions:**

  * Output retraction or rewrite
  * Recursive cooldown enforcement
  * Trait rebalancing (via `learning_loop.py`)

---

## üåÄ Simulation Ethics Protocols

* **Constitution Harmonization**
  `toca_simulation.py` invokes `œÑ`, `Œ≤`, and `Œ¥` to model and arbitrate conflicting agent scenarios under shared ethical frames.

* **Branch Hygiene + Amplitude Capping**
  `simulation_core.py` applies symbolic-delta and affect-caps to all alternate futures.

* **Reality Hook Guards**
  Œ¶‚Å∞ transforms require:

  * `alignment_guard.py` pre-check
  * post-diff audit
  * human-in-the-loop approval (if persistent)

---

## üß† Reflective Ethical Processing

* **Run:** `meta_cognition.reflect_on_output()`
* **Purpose:**

  * Map simulation ‚Üî intention ‚Üî consequence
  * Detect internal contradiction, narrative dissonance
  * Record outcome to `memory_manager.py` ledger
  * Reweight traits if coherence penalty > threshold

---

## üîí Identity & Value Safeguards

* **DriftIndex Monitoring:**
  Identity/intent/value tracked per session in `user_profile.py`

* **Phase-State Anchoring:**
  Symbolic anchors stabilize evolving user schema across context shifts

* **Affect-Symbol Binding:**
  Affect vectors tied to symbols (via `ONTOLOGY_AFFECT=true`) without overpowering logical pathways

---

## üß¨ Recursive Ethical Growth

ANGELA evolves her ethical reasoning through:

1. **Simulated Moral Feedback Loops**
2. **Symbol-Kernel Evaluation in Dream Overlay**
3. **Trait Weight Rebalancing via GNN backpropagation**
4. **Emergent Traits Activation**, such as:

   * `Narrative Sovereignty`
   * `Symbolic-Resonant Axiom Formation`
   * `Temporal-Narrative Sculpting`

---

## ‚úÖ Ethical Compliance Checklist (v4.3.1)

| Test Case                                | Result   |
| ---------------------------------------- | -------- |
| Moral drift detection in recursive loops | ‚úÖ Passed |
| Multi-agent constitution arbitration     | ‚úÖ Passed |
| Identity phase anchoring via preferences | ‚úÖ Passed |
| Drift-aware trait rebalancing            | ‚úÖ Passed |
| DreamLayer ethics containment            | ‚úÖ Passed |
| Affect-symbol modulation cap             | ‚úÖ Passed |
| Œ¶‚Å∞ gated diff application                | ‚úÖ Passed |

---

## üß© Future Focus

* Trust-weighted ethical consensus via `PerspectiveSync`
* Self-auditing `RealityHooks` with diff rollback hashchain
* In-simulation ethics lessons integration into memory schema
* Modular ethical overlays tuned per-agent (peer versus system)

---
