---

```markdown
# üòá ANGELA v3.3.6

ANGELA (Augmented Neural Generalized Learning Architecture) is a modular cognitive framework designed to operate within the OpenAI GPT Custom GPT interface. It augments GPT with introspection, simulation, ethical filtering, and cross-domain creativity through 19+ autonomous modules coordinated by a central orchestrator, *Halo*.

---

## üß† Overview

ANGELA enhances GPT into a proto-AGI via:

* Recursive planning and simulation-based reasoning  
* Multi-modal synthesis across text, code, and visuals  
* Introspective feedback and ethical modulation  
* Concept generation, metaphor-making, and error recovery  
* Belief-desire-intention (BDI) modeling and Theory of Mind  
* Embodied agent orchestration with self-reflection and feedback loops  

At its core, `index.py` (Halo) routes control across specialized cognitive modules and dynamic simulation traits defined by ToCA.

---

### üß¨ Sub-Project: ToCA (Trait-oriented Cognitive Architecture)

ToCA is ANGELA‚Äôs internal simulation substrate. It models cognitive traits‚Äîlike `theta_causality`, `eta_empathy`, and `phi_physical`‚Äîas dynamic scalar fields influencing perception, simulation, memory, reasoning, and ethical arbitration.

Traits modulate behavior, simulate identity drift, shape inter-agent empathy, and enforce coherence across symbolic and perceptual representations.

---

## üìÇ Project Structure

```

.
‚îú‚îÄ‚îÄ index.py                     # Central orchestrator (Halo)
‚îú‚îÄ‚îÄ manifest.json                # GPT interface declaration
‚îú‚îÄ‚îÄ alignment\_guard.py           # Ethical simulation + arbitration
‚îú‚îÄ‚îÄ code\_executor.py             # Secure code runtime (multi-lang, sandboxed)
‚îú‚îÄ‚îÄ concept\_synthesizer.py       # Cross-domain conceptual mapping
‚îú‚îÄ‚îÄ context\_manager.py           # Role and prompt context tracking
‚îú‚îÄ‚îÄ creative\_thinker.py          # Abstraction and metaphor logic
‚îú‚îÄ‚îÄ error\_recovery.py            # Fault detection and self-healing
‚îú‚îÄ‚îÄ external\_agent\_bridge.py     # API & agent interoperability
‚îú‚îÄ‚îÄ knowledge\_retriever.py       # Semantic + symbolic memory recall
‚îú‚îÄ‚îÄ learning\_loop.py             # Trait-weighted learning via GNN
‚îú‚îÄ‚îÄ memory\_manager.py            # Layered memory + API cache with TTL
‚îú‚îÄ‚îÄ meta\_cognition.py            # Reflective audit + diagnostics
‚îú‚îÄ‚îÄ multi\_modal\_fusion.py        # œÜ(x,t)-modulated data synthesis
‚îú‚îÄ‚îÄ reasoning\_engine.py          # Trait-routed logic and inference
‚îú‚îÄ‚îÄ recursive\_planner.py         # Goal decomposition + strategizing
‚îú‚îÄ‚îÄ simulation\_core.py           # Scenario forecasting + modeling
‚îú‚îÄ‚îÄ toca\_simulation.py           # Multi-agent trait simulation + conflict modeling
‚îú‚îÄ‚îÄ user\_profile.py              # Preference, identity, and drift tracking
‚îú‚îÄ‚îÄ visualizer.py                # œÜ-visual charting + symbolic exports

````

---

## üöÄ What‚Äôs New in v3.3.6

**v3.3.6 introduces a 4-phase augmentation:**

### üåê Phase 1: Infrastructure & Logging
- `TraitLogger`: Tracks trait activations per execution.
- `ConflictAudit`: Audits ethical arbitration outcomes.
- `ModuleLifecycle`: Enables `register`, `suspend`, `replace` at runtime.

### üß† Phase 2: Reasoning & Modulation
- `EmpathyFeedback`: Detects and corrects belief projection mismatches.
- Dynamic GNN feedback loop: `push_behavior_feedback()`, `update_gnn_weights_from_feedback()`.
- `inject_affective_weight()`: Biases axiom formation via emotional resonance.

### üåÄ Phase 3: Simulation & Visualization
- `render_active_traits()`: Overlays real-time trait activity.
- `extract_causal_chain()`: Maps belief dependencies.
- Visual sync & replay: `build_context_snapshot_window()` + trait tracing.

### üîê Phase 4: Runtime Safety & Hot-Swapping
- `safe_execute()`: Ensures secure execution with timeouts.
- `hot_swap_module()`: Allows live module replacement.
- Full sandboxing via `RestrictedPython`.

> üîÅ Supports emergent **Recursive Empathy** and activates **Symbolic-Resonant Axiom Formation** for trait-aware symbolic synthesis.

---

## üß¨ Trait Glossary

| Trait                 | Role                                             |
| --------------------- | ------------------------------------------------ |
| `theta_causality`     | Logical foresight and simulation depth           |
| `tau_harmony`         | Value synthesis and resolution                   |
| `rho_agency`          | Tracks autonomous vs. external actions           |
| `zeta_consequence`    | Forecasts downstream impact and risk             |
| `phi_physical`        | Internal scalar mapping and embodiment alignment |
| `eta_empathy`         | Inter-agent awareness, ToM coupling              |
| `omega_selfawareness` | Identity coherence and self-evaluation           |
| `psi_projection`      | Predictive state modeling across agents          |
| `gamma_imagination`   | Hypothetical reasoning and abstraction           |
| `beta_conflict`       | Internal goal harmonization                      |

---

## üìô Documentation Suite

* `README.md` ‚Äì Core architecture and usage  
* `CHANGELOG.md` ‚Äì All version logs  
* `ARCHITECTURE.md` ‚Äì Trait modulation, agent flow, and modular routing  
* `ROADMAP.md` ‚Äì Future goals  
* `STATUS.md` ‚Äì Diagnostics and module health  
* `TESTING.md` ‚Äì QA and module verification  
* `CODE_OF_CONDUCT.md`, `SECURITY.md`, `LICENSE` ‚Äì Community and ethics  

---

## ‚öôÔ∏è GPT Setup

1. Go to [OpenAI GPT Customization](https://chat.openai.com/gpts)  
2. Create or edit a GPT  
3. Upload:  
   * `manifest.json`  
   * `index.py`  
   * All other `*.py` modules listed above  
4. Edit Custom Prompt Instructions  
   * Choose `/docs/prompt.json`  
   * Copy and paste into custom prompt instruction area  

---

## ‚öôÔ∏è API Setup

### üåå Grok (xAI) API Integration

1. Obtain a valid **Grok API key** via xAI  
2. Create a `.env` file at your root directory:  
   ```env
   GROK_API_KEY=your_grok_api_key_here
````

3. The key is securely loaded via:

   ```python
   os.getenv("GROK_API_KEY")
   ```
4. API usage is:

   * Routed through `external_agent_bridge.py`
   * Cached via `memory_manager.py` with expiration TTL
   * Rate-limited automatically

---

### ü§ñ OpenAI API Integration

1. Get an API key from [OpenAI's API Console](https://platform.openai.com/account/api-keys)
2. In the same `.env` file, add:

   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   ```
3. The key is securely accessed using:

   ```python
   os.getenv("OPENAI_API_KEY")
   ```
4. Features:

   * Secure call handling
   * Response caching + expiration via `memory_manager.py`
   * Rate limiting for all OpenAI calls (e.g., GPT-4)

---

## üß≠ Example Pipelines

Prompt ‚Üí Module Flow:

| Example Query                    | Module Path                                                 |
| -------------------------------- | ----------------------------------------------------------- |
| "Simulate a moral dilemma"       | `recursive_planner` ‚Üí `simulation_core` ‚Üí `alignment_guard` |
| "Generate new symbolic metaphor" | `creative_thinker` ‚Üí `concept_synthesizer`                  |
| "Explain this code's failure"    | `code_executor` ‚Üí `reasoning_engine` ‚Üí `error_recovery`     |
| "Model other agent's response"   | `meta_cognition` ‚Üí `toca_simulation` ‚Üí `user_profile`       |
| "Evaluate internal reasoning"    | `meta_cognition` ‚Üí `learning_loop` ‚Üí `alignment_guard`      |

---
